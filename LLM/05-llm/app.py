from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import hub
import os
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain_community.document_loaders import PyPDFLoader

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("OPENAI_API_KEY bulunamadÄ±.")


#Pdf dosyasini al documentsta isleme hazir hale getir
file_path = r"C:\Users\slayer\Desktop\KAÄ°RU\LLM-portfolio\05-llm\ML 00 Makine OÌˆgÌ†renmesi GirisÌ§.pdf"

if not os.path.exists(file_path) :
    raise FileNotFoundError(f"PDF  DOSYASI BULUNAMADI :  {file_path}")

loader = PyPDFLoader(file_path)
documents = loader.load()

#Metni kucuk parcalara ayiriyoruz cunku context windowa takilmak istemiyorum
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
text = splitter.split_documents(documents)

#daha sonra hizlica arama yapmak icin vektor veri tabanina saklama yapmak adina vector embedding yapiyoruz
embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)
db=FAISS.from_documents(text, embedding_model)

#llm
llm = ChatOpenAI(
    model_name="gpt-4",
    temperature=0.7,
    streaming=True,
    openai_api_key=openai_api_key
    )

#llm ile vektor veri tabanini birbirine baglayarak mekanizmayi olusturur
retriever = db.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm=llm,  retriever=retriever)

#asistanÄ±nÄ±za konuÅŸma hafÄ±zasÄ± kazandÄ±rÄ±r
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

konular = {
    "makine oÄŸrenmesi nedir?": "Makine Ã–ÄŸrenmesi Nedir?",
    "makine oÄŸrenmesi uygulama adÄ±mlarÄ±": "Makine Ã–ÄŸrenmesi Uygulama AdÄ±mlarÄ±",
    "makine oÄŸrenmesi tÃ¼rleri": "Makine Ã–ÄŸrenmesi TÃ¼rleri",
    "makine oÄŸrenmesinde performans paremetreleri": "Makine Ã–ÄŸrenmesinde Performans Paremetreleri"
}

# --------- Sohbet BaÅŸlat ---------
print("ML Mentor AsistanÄ± BaÅŸladÄ± (Ã‡Ä±kmak iÃ§in 'Ã§Ä±k' yazÄ±n)\n")

# Ã–ÄŸrenilen konular listesi
ogrenilen_konular = set()

while True:
    user_input = input("ğŸ‘¤ Siz: ")
    if user_input.lower() in ["Ã§Ä±k", "exit"]:
        print("GÃ¶rÃ¼ÅŸmek Ã¼zere!")
        break

    # Geri Bildirim Ä°steÄŸi KontrolÃ¼
    if "bugÃ¼n ne Ã¶ÄŸrendim" in user_input.lower() or "geri bildirim" in user_input.lower():
        print("\nğŸ¤– Asistan (Geri Bildirim):")

        if ogrenilen_konular:
            print("BugÃ¼n Ã¶ÄŸrendiÄŸiniz konular:")
            for konu in ogrenilen_konular:
                print(f"- {konu}")
        else:
            print("- HenÃ¼z bir konu Ã¼zerinde konuÅŸmadÄ±k.")

        eksik_konular = set(konular.values()) - ogrenilen_konular
        if eksik_konular:
            print("\nEksik kalan konular:")
            for konu in eksik_konular:
                print(f"- {konu}")
            print("\nBu konulara da gÃ¶z atmanÄ±zÄ± Ã¶neririm.")
        else:
            print("\nTebrikler! TÃ¼m temel konularÄ± Ã¶ÄŸrendiniz.")
        continue

    # QA Zincirinden cevap al
    response = qa_chain.invoke(user_input)
    print("ğŸ¤– Asistan:", response)

    # Konu Ã§Ä±karÄ±mÄ±
    for anahtar, konu in konular.items():
        if anahtar in user_input.lower():
            ogrenilen_konular.add(konu)